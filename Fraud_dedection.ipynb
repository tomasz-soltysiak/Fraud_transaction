{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fraud_dedection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomasz-soltysiak/Fraud_transaction/blob/oversampling/Fraud_dedection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G76CWpZzuWhu",
        "colab_type": "code",
        "outputId": "a9c46581-a844-4989-9db7-65597a7007dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score,roc_curve,confusion_matrix,roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "! pip install joblib\n",
        "from joblib import dump, load\n",
        "from mlxtend.classifier import EnsembleVoteClassifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.14.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EcDK9tkXMnw",
        "colab_type": "code",
        "outputId": "c795d235-a6aa-456f-ffa3-e7b1e2497d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90xbXAp08Qb2",
        "colab_type": "text"
      },
      "source": [
        "After adding libraries, I upload data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvdgXIvk8gLT",
        "colab_type": "code",
        "outputId": "98780417-9177-40c8-fdf5-71da63963156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "#df=pd.read_csv('/content/drive/My Drive/Data Science/ML fraud detection/data.csv')\n",
        "df=pd.read_csv('/content/drive/My Drive/Colab Notebooks/data.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127614.0</td>\n",
              "      <td>2.004188</td>\n",
              "      <td>-0.287498</td>\n",
              "      <td>-1.984934</td>\n",
              "      <td>0.342239</td>\n",
              "      <td>0.413188</td>\n",
              "      <td>-0.815346</td>\n",
              "      <td>0.445456</td>\n",
              "      <td>-0.299258</td>\n",
              "      <td>0.562445</td>\n",
              "      <td>0.109932</td>\n",
              "      <td>-1.381862</td>\n",
              "      <td>-0.428037</td>\n",
              "      <td>-1.230877</td>\n",
              "      <td>0.629739</td>\n",
              "      <td>-0.242149</td>\n",
              "      <td>-0.388169</td>\n",
              "      <td>-0.137390</td>\n",
              "      <td>-0.552790</td>\n",
              "      <td>0.315548</td>\n",
              "      <td>-0.152272</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>-0.127194</td>\n",
              "      <td>0.036464</td>\n",
              "      <td>0.504076</td>\n",
              "      <td>0.176423</td>\n",
              "      <td>0.541252</td>\n",
              "      <td>-0.121212</td>\n",
              "      <td>-0.064948</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139389.0</td>\n",
              "      <td>2.346905</td>\n",
              "      <td>-1.264915</td>\n",
              "      <td>-1.034900</td>\n",
              "      <td>-1.568721</td>\n",
              "      <td>-1.122435</td>\n",
              "      <td>-0.790624</td>\n",
              "      <td>-1.011732</td>\n",
              "      <td>-0.268243</td>\n",
              "      <td>-1.229191</td>\n",
              "      <td>1.576645</td>\n",
              "      <td>-1.286030</td>\n",
              "      <td>-0.816409</td>\n",
              "      <td>0.603102</td>\n",
              "      <td>-0.437890</td>\n",
              "      <td>-0.164642</td>\n",
              "      <td>-0.582255</td>\n",
              "      <td>0.427399</td>\n",
              "      <td>-0.134499</td>\n",
              "      <td>-0.049048</td>\n",
              "      <td>-0.460329</td>\n",
              "      <td>-0.196288</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.197023</td>\n",
              "      <td>-0.432445</td>\n",
              "      <td>-0.119139</td>\n",
              "      <td>-0.131627</td>\n",
              "      <td>0.015176</td>\n",
              "      <td>-0.058104</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68482.0</td>\n",
              "      <td>-3.089671</td>\n",
              "      <td>2.464689</td>\n",
              "      <td>0.042745</td>\n",
              "      <td>1.670674</td>\n",
              "      <td>-2.129076</td>\n",
              "      <td>0.600262</td>\n",
              "      <td>-1.627286</td>\n",
              "      <td>2.452801</td>\n",
              "      <td>0.319063</td>\n",
              "      <td>-0.526330</td>\n",
              "      <td>-1.681347</td>\n",
              "      <td>1.951140</td>\n",
              "      <td>1.001432</td>\n",
              "      <td>0.346440</td>\n",
              "      <td>-1.625289</td>\n",
              "      <td>-1.128464</td>\n",
              "      <td>1.888585</td>\n",
              "      <td>-1.045530</td>\n",
              "      <td>1.149073</td>\n",
              "      <td>-0.060298</td>\n",
              "      <td>-0.223384</td>\n",
              "      <td>-0.441265</td>\n",
              "      <td>0.250283</td>\n",
              "      <td>0.091483</td>\n",
              "      <td>-0.038373</td>\n",
              "      <td>-0.410096</td>\n",
              "      <td>0.088944</td>\n",
              "      <td>0.026973</td>\n",
              "      <td>30.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123677.0</td>\n",
              "      <td>1.792358</td>\n",
              "      <td>-0.384458</td>\n",
              "      <td>-2.170063</td>\n",
              "      <td>0.096243</td>\n",
              "      <td>0.291162</td>\n",
              "      <td>-1.510182</td>\n",
              "      <td>0.921037</td>\n",
              "      <td>-0.525263</td>\n",
              "      <td>-0.088484</td>\n",
              "      <td>0.119203</td>\n",
              "      <td>1.171025</td>\n",
              "      <td>1.013250</td>\n",
              "      <td>-0.123025</td>\n",
              "      <td>1.041171</td>\n",
              "      <td>-0.323426</td>\n",
              "      <td>-0.460035</td>\n",
              "      <td>-0.465857</td>\n",
              "      <td>-0.061338</td>\n",
              "      <td>0.309959</td>\n",
              "      <td>0.072457</td>\n",
              "      <td>0.297749</td>\n",
              "      <td>0.633531</td>\n",
              "      <td>-0.176001</td>\n",
              "      <td>0.146116</td>\n",
              "      <td>0.342753</td>\n",
              "      <td>0.198887</td>\n",
              "      <td>-0.117734</td>\n",
              "      <td>-0.061706</td>\n",
              "      <td>154.09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121222.0</td>\n",
              "      <td>2.188008</td>\n",
              "      <td>-0.400212</td>\n",
              "      <td>-1.627908</td>\n",
              "      <td>-0.225692</td>\n",
              "      <td>-0.133549</td>\n",
              "      <td>-1.273351</td>\n",
              "      <td>0.226144</td>\n",
              "      <td>-0.553975</td>\n",
              "      <td>-0.908684</td>\n",
              "      <td>0.877520</td>\n",
              "      <td>-0.845913</td>\n",
              "      <td>0.763512</td>\n",
              "      <td>1.478457</td>\n",
              "      <td>0.027869</td>\n",
              "      <td>-0.734253</td>\n",
              "      <td>-2.244708</td>\n",
              "      <td>0.184697</td>\n",
              "      <td>0.251184</td>\n",
              "      <td>-0.646467</td>\n",
              "      <td>-0.558023</td>\n",
              "      <td>-0.338599</td>\n",
              "      <td>-0.220436</td>\n",
              "      <td>0.112804</td>\n",
              "      <td>0.049313</td>\n",
              "      <td>0.157236</td>\n",
              "      <td>0.606729</td>\n",
              "      <td>-0.063450</td>\n",
              "      <td>-0.071105</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0  127614.0  2.004188 -0.287498 -1.984934  ... -0.121212 -0.064948   64.99      0\n",
              "1  139389.0  2.346905 -1.264915 -1.034900  ...  0.015176 -0.058104    1.00      0\n",
              "2   68482.0 -3.089671  2.464689  0.042745  ...  0.088944  0.026973   30.70      0\n",
              "3  123677.0  1.792358 -0.384458 -2.170063  ... -0.117734 -0.061706  154.09      0\n",
              "4  121222.0  2.188008 -0.400212 -1.627908  ... -0.063450 -0.071105   10.00      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6mq03sf3X8v",
        "colab_type": "code",
        "outputId": "f6a58c05-1c5e-4c27-b4f2-b37183e3949b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "df=df.dropna(axis=0)\n",
        "df.isnull().sum(axis=0)\n",
        "df.head(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127614.0</td>\n",
              "      <td>2.004188</td>\n",
              "      <td>-0.287498</td>\n",
              "      <td>-1.984934</td>\n",
              "      <td>0.342239</td>\n",
              "      <td>0.413188</td>\n",
              "      <td>-0.815346</td>\n",
              "      <td>0.445456</td>\n",
              "      <td>-0.299258</td>\n",
              "      <td>0.562445</td>\n",
              "      <td>0.109932</td>\n",
              "      <td>-1.381862</td>\n",
              "      <td>-0.428037</td>\n",
              "      <td>-1.230877</td>\n",
              "      <td>0.629739</td>\n",
              "      <td>-0.242149</td>\n",
              "      <td>-0.388169</td>\n",
              "      <td>-0.13739</td>\n",
              "      <td>-0.55279</td>\n",
              "      <td>0.315548</td>\n",
              "      <td>-0.152272</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>-0.127194</td>\n",
              "      <td>0.036464</td>\n",
              "      <td>0.504076</td>\n",
              "      <td>0.176423</td>\n",
              "      <td>0.541252</td>\n",
              "      <td>-0.121212</td>\n",
              "      <td>-0.064948</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0  127614.0  2.004188 -0.287498 -1.984934  ... -0.121212 -0.064948   64.99      0\n",
              "\n",
              "[1 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJM2bry9371i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.floor((172792/3600)%24)\n",
        "np.floor((89000/3600)%24)\n",
        "df['scaled_time']=round((df['Time']/3600)%24)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4eb42474-591c-4865-a03a-6e5084eb08ee",
        "id": "szIZFYEGfJpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "Rob_scaler=RobustScaler()\n",
        "\n",
        "df['scaled_Amount']=Rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>scaled_Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127614.0</td>\n",
              "      <td>2.004188</td>\n",
              "      <td>-0.287498</td>\n",
              "      <td>-1.984934</td>\n",
              "      <td>0.342239</td>\n",
              "      <td>0.413188</td>\n",
              "      <td>-0.815346</td>\n",
              "      <td>0.445456</td>\n",
              "      <td>-0.299258</td>\n",
              "      <td>0.562445</td>\n",
              "      <td>0.109932</td>\n",
              "      <td>-1.381862</td>\n",
              "      <td>-0.428037</td>\n",
              "      <td>-1.230877</td>\n",
              "      <td>0.629739</td>\n",
              "      <td>-0.242149</td>\n",
              "      <td>-0.388169</td>\n",
              "      <td>-0.137390</td>\n",
              "      <td>-0.552790</td>\n",
              "      <td>0.315548</td>\n",
              "      <td>-0.152272</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>-0.127194</td>\n",
              "      <td>0.036464</td>\n",
              "      <td>0.504076</td>\n",
              "      <td>0.176423</td>\n",
              "      <td>0.541252</td>\n",
              "      <td>-0.121212</td>\n",
              "      <td>-0.064948</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.601848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139389.0</td>\n",
              "      <td>2.346905</td>\n",
              "      <td>-1.264915</td>\n",
              "      <td>-1.034900</td>\n",
              "      <td>-1.568721</td>\n",
              "      <td>-1.122435</td>\n",
              "      <td>-0.790624</td>\n",
              "      <td>-1.011732</td>\n",
              "      <td>-0.268243</td>\n",
              "      <td>-1.229191</td>\n",
              "      <td>1.576645</td>\n",
              "      <td>-1.286030</td>\n",
              "      <td>-0.816409</td>\n",
              "      <td>0.603102</td>\n",
              "      <td>-0.437890</td>\n",
              "      <td>-0.164642</td>\n",
              "      <td>-0.582255</td>\n",
              "      <td>0.427399</td>\n",
              "      <td>-0.134499</td>\n",
              "      <td>-0.049048</td>\n",
              "      <td>-0.460329</td>\n",
              "      <td>-0.196288</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.197023</td>\n",
              "      <td>-0.432445</td>\n",
              "      <td>-0.119139</td>\n",
              "      <td>-0.131627</td>\n",
              "      <td>0.015176</td>\n",
              "      <td>-0.058104</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-0.293994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68482.0</td>\n",
              "      <td>-3.089671</td>\n",
              "      <td>2.464689</td>\n",
              "      <td>0.042745</td>\n",
              "      <td>1.670674</td>\n",
              "      <td>-2.129076</td>\n",
              "      <td>0.600262</td>\n",
              "      <td>-1.627286</td>\n",
              "      <td>2.452801</td>\n",
              "      <td>0.319063</td>\n",
              "      <td>-0.526330</td>\n",
              "      <td>-1.681347</td>\n",
              "      <td>1.951140</td>\n",
              "      <td>1.001432</td>\n",
              "      <td>0.346440</td>\n",
              "      <td>-1.625289</td>\n",
              "      <td>-1.128464</td>\n",
              "      <td>1.888585</td>\n",
              "      <td>-1.045530</td>\n",
              "      <td>1.149073</td>\n",
              "      <td>-0.060298</td>\n",
              "      <td>-0.223384</td>\n",
              "      <td>-0.441265</td>\n",
              "      <td>0.250283</td>\n",
              "      <td>0.091483</td>\n",
              "      <td>-0.038373</td>\n",
              "      <td>-0.410096</td>\n",
              "      <td>0.088944</td>\n",
              "      <td>0.026973</td>\n",
              "      <td>30.70</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.121798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123677.0</td>\n",
              "      <td>1.792358</td>\n",
              "      <td>-0.384458</td>\n",
              "      <td>-2.170063</td>\n",
              "      <td>0.096243</td>\n",
              "      <td>0.291162</td>\n",
              "      <td>-1.510182</td>\n",
              "      <td>0.921037</td>\n",
              "      <td>-0.525263</td>\n",
              "      <td>-0.088484</td>\n",
              "      <td>0.119203</td>\n",
              "      <td>1.171025</td>\n",
              "      <td>1.013250</td>\n",
              "      <td>-0.123025</td>\n",
              "      <td>1.041171</td>\n",
              "      <td>-0.323426</td>\n",
              "      <td>-0.460035</td>\n",
              "      <td>-0.465857</td>\n",
              "      <td>-0.061338</td>\n",
              "      <td>0.309959</td>\n",
              "      <td>0.072457</td>\n",
              "      <td>0.297749</td>\n",
              "      <td>0.633531</td>\n",
              "      <td>-0.176001</td>\n",
              "      <td>0.146116</td>\n",
              "      <td>0.342753</td>\n",
              "      <td>0.198887</td>\n",
              "      <td>-0.117734</td>\n",
              "      <td>-0.061706</td>\n",
              "      <td>154.09</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.849223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121222.0</td>\n",
              "      <td>2.188008</td>\n",
              "      <td>-0.400212</td>\n",
              "      <td>-1.627908</td>\n",
              "      <td>-0.225692</td>\n",
              "      <td>-0.133549</td>\n",
              "      <td>-1.273351</td>\n",
              "      <td>0.226144</td>\n",
              "      <td>-0.553975</td>\n",
              "      <td>-0.908684</td>\n",
              "      <td>0.877520</td>\n",
              "      <td>-0.845913</td>\n",
              "      <td>0.763512</td>\n",
              "      <td>1.478457</td>\n",
              "      <td>0.027869</td>\n",
              "      <td>-0.734253</td>\n",
              "      <td>-2.244708</td>\n",
              "      <td>0.184697</td>\n",
              "      <td>0.251184</td>\n",
              "      <td>-0.646467</td>\n",
              "      <td>-0.558023</td>\n",
              "      <td>-0.338599</td>\n",
              "      <td>-0.220436</td>\n",
              "      <td>0.112804</td>\n",
              "      <td>0.049313</td>\n",
              "      <td>0.157236</td>\n",
              "      <td>0.606729</td>\n",
              "      <td>-0.063450</td>\n",
              "      <td>-0.071105</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-0.167997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2  ...  Class  scaled_time  scaled_Amount\n",
              "0  127614.0  2.004188 -0.287498  ...      0         11.0       0.601848\n",
              "1  139389.0  2.346905 -1.264915  ...      0         15.0      -0.293994\n",
              "2   68482.0 -3.089671  2.464689  ...      0         19.0       0.121798\n",
              "3  123677.0  1.792358 -0.384458  ...      0         10.0       1.849223\n",
              "4  121222.0  2.188008 -0.400212  ...      0         10.0      -0.167997\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZp8Oy-SaP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "df_X = df.iloc[:, 0:32]\n",
        "X_resampled, y_resampled = ros.fit_resample(df_X, df['Class'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux7iTzor9te8",
        "colab_type": "code",
        "outputId": "e88cb8bd-1d14-49df-919f-1f4faab34f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "X_resampled_cols = list(df.columns.values)\n",
        "X_resampled_cols.remove('Class')\n",
        "df_ovsmpl = pd.DataFrame(X_resampled, columns=X_resampled_cols)\n",
        "df_ovsmpl['Class']=pd.DataFrame(y_resampled)\n",
        "df_ovsmpl.head()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>scaled_Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127614.0</td>\n",
              "      <td>2.004188</td>\n",
              "      <td>-0.287498</td>\n",
              "      <td>-1.984934</td>\n",
              "      <td>0.342239</td>\n",
              "      <td>0.413188</td>\n",
              "      <td>-0.815346</td>\n",
              "      <td>0.445456</td>\n",
              "      <td>-0.299258</td>\n",
              "      <td>0.562445</td>\n",
              "      <td>0.109932</td>\n",
              "      <td>-1.381862</td>\n",
              "      <td>-0.428037</td>\n",
              "      <td>-1.230877</td>\n",
              "      <td>0.629739</td>\n",
              "      <td>-0.242149</td>\n",
              "      <td>-0.388169</td>\n",
              "      <td>-0.137390</td>\n",
              "      <td>-0.552790</td>\n",
              "      <td>0.315548</td>\n",
              "      <td>-0.152272</td>\n",
              "      <td>-0.038661</td>\n",
              "      <td>-0.127194</td>\n",
              "      <td>0.036464</td>\n",
              "      <td>0.504076</td>\n",
              "      <td>0.176423</td>\n",
              "      <td>0.541252</td>\n",
              "      <td>-0.121212</td>\n",
              "      <td>-0.064948</td>\n",
              "      <td>64.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>139389.0</td>\n",
              "      <td>2.346905</td>\n",
              "      <td>-1.264915</td>\n",
              "      <td>-1.034900</td>\n",
              "      <td>-1.568721</td>\n",
              "      <td>-1.122435</td>\n",
              "      <td>-0.790624</td>\n",
              "      <td>-1.011732</td>\n",
              "      <td>-0.268243</td>\n",
              "      <td>-1.229191</td>\n",
              "      <td>1.576645</td>\n",
              "      <td>-1.286030</td>\n",
              "      <td>-0.816409</td>\n",
              "      <td>0.603102</td>\n",
              "      <td>-0.437890</td>\n",
              "      <td>-0.164642</td>\n",
              "      <td>-0.582255</td>\n",
              "      <td>0.427399</td>\n",
              "      <td>-0.134499</td>\n",
              "      <td>-0.049048</td>\n",
              "      <td>-0.460329</td>\n",
              "      <td>-0.196288</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.197023</td>\n",
              "      <td>-0.432445</td>\n",
              "      <td>-0.119139</td>\n",
              "      <td>-0.131627</td>\n",
              "      <td>0.015176</td>\n",
              "      <td>-0.058104</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>68482.0</td>\n",
              "      <td>-3.089671</td>\n",
              "      <td>2.464689</td>\n",
              "      <td>0.042745</td>\n",
              "      <td>1.670674</td>\n",
              "      <td>-2.129076</td>\n",
              "      <td>0.600262</td>\n",
              "      <td>-1.627286</td>\n",
              "      <td>2.452801</td>\n",
              "      <td>0.319063</td>\n",
              "      <td>-0.526330</td>\n",
              "      <td>-1.681347</td>\n",
              "      <td>1.951140</td>\n",
              "      <td>1.001432</td>\n",
              "      <td>0.346440</td>\n",
              "      <td>-1.625289</td>\n",
              "      <td>-1.128464</td>\n",
              "      <td>1.888585</td>\n",
              "      <td>-1.045530</td>\n",
              "      <td>1.149073</td>\n",
              "      <td>-0.060298</td>\n",
              "      <td>-0.223384</td>\n",
              "      <td>-0.441265</td>\n",
              "      <td>0.250283</td>\n",
              "      <td>0.091483</td>\n",
              "      <td>-0.038373</td>\n",
              "      <td>-0.410096</td>\n",
              "      <td>0.088944</td>\n",
              "      <td>0.026973</td>\n",
              "      <td>30.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123677.0</td>\n",
              "      <td>1.792358</td>\n",
              "      <td>-0.384458</td>\n",
              "      <td>-2.170063</td>\n",
              "      <td>0.096243</td>\n",
              "      <td>0.291162</td>\n",
              "      <td>-1.510182</td>\n",
              "      <td>0.921037</td>\n",
              "      <td>-0.525263</td>\n",
              "      <td>-0.088484</td>\n",
              "      <td>0.119203</td>\n",
              "      <td>1.171025</td>\n",
              "      <td>1.013250</td>\n",
              "      <td>-0.123025</td>\n",
              "      <td>1.041171</td>\n",
              "      <td>-0.323426</td>\n",
              "      <td>-0.460035</td>\n",
              "      <td>-0.465857</td>\n",
              "      <td>-0.061338</td>\n",
              "      <td>0.309959</td>\n",
              "      <td>0.072457</td>\n",
              "      <td>0.297749</td>\n",
              "      <td>0.633531</td>\n",
              "      <td>-0.176001</td>\n",
              "      <td>0.146116</td>\n",
              "      <td>0.342753</td>\n",
              "      <td>0.198887</td>\n",
              "      <td>-0.117734</td>\n",
              "      <td>-0.061706</td>\n",
              "      <td>154.09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121222.0</td>\n",
              "      <td>2.188008</td>\n",
              "      <td>-0.400212</td>\n",
              "      <td>-1.627908</td>\n",
              "      <td>-0.225692</td>\n",
              "      <td>-0.133549</td>\n",
              "      <td>-1.273351</td>\n",
              "      <td>0.226144</td>\n",
              "      <td>-0.553975</td>\n",
              "      <td>-0.908684</td>\n",
              "      <td>0.877520</td>\n",
              "      <td>-0.845913</td>\n",
              "      <td>0.763512</td>\n",
              "      <td>1.478457</td>\n",
              "      <td>0.027869</td>\n",
              "      <td>-0.734253</td>\n",
              "      <td>-2.244708</td>\n",
              "      <td>0.184697</td>\n",
              "      <td>0.251184</td>\n",
              "      <td>-0.646467</td>\n",
              "      <td>-0.558023</td>\n",
              "      <td>-0.338599</td>\n",
              "      <td>-0.220436</td>\n",
              "      <td>0.112804</td>\n",
              "      <td>0.049313</td>\n",
              "      <td>0.157236</td>\n",
              "      <td>0.606729</td>\n",
              "      <td>-0.063450</td>\n",
              "      <td>-0.071105</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2  ...  scaled_time  scaled_Amount  Class\n",
              "0  127614.0  2.004188 -0.287498  ...          0.0           11.0      0\n",
              "1  139389.0  2.346905 -1.264915  ...          0.0           15.0      0\n",
              "2   68482.0 -3.089671  2.464689  ...          0.0           19.0      0\n",
              "3  123677.0  1.792358 -0.384458  ...          0.0           10.0      0\n",
              "4  121222.0  2.188008 -0.400212  ...          0.0           10.0      0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGky2VXgsTJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ovsmpl.to_csv('df_ovsmpl.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xKxa72asbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ovsmpl=df_ovsmpl.drop(['Time','Amount'],axis=1)\n",
        "df_ovsmpl.head()\n",
        "\n",
        "X_train=df_ovsmpl.drop(columns=['Class'],axis=1)\n",
        "y_train=df_ovsmpl['Class']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nchtHslDcl8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Log_reg(X,y):\n",
        "  \n",
        "  log_reg=LogisticRegression()\n",
        "  penalty=['l1','l2']\n",
        "  C=np.arange(2,12,2)\n",
        "  class_weight=['balanced']\n",
        "  \n",
        "  random_state=[20,42,64,100]\n",
        "  hyperpara=dict(penalty=penalty,C=C,class_weight=class_weight,random_state=random_state)\n",
        "  \n",
        "  LR = RandomizedSearchCV(log_reg,hyperpara,cv=5,verbose=0,scoring='precision').fit(X,y)\n",
        "\n",
        "\n",
        "  return LR\n",
        "\n",
        "def Rand_forest(X,y):\n",
        "  rf=RandomForestClassifier()\n",
        "\n",
        "  n_estimators=np.arange(3,200,50)\n",
        "  criterion=['gini','entropy']\n",
        "  max_depth=np.arange(2,14,2)\n",
        "  min_samples_split=np.arange(2,20,2)\n",
        "  bootstrap=[True,False]\n",
        "  warm_start=[True,False]\n",
        "  class_weight=['balanced','balanced_subsample']\n",
        "  hyperpara=dict(n_estimators=n_estimators,criterion=criterion,max_depth=max_depth)\n",
        "  RF = RandomizedSearchCV(rf,hyperpara,cv=5,verbose=0,scoring='precision').fit(X,y)\n",
        "\n",
        "  return RF\n",
        "\n",
        "def KNeig(X,y):\n",
        "  Kneig=KNeighborsClassifier()\n",
        "  n_neighbors=np.arange(2,12,2)\n",
        "  weights=['uniform','distance']\n",
        "  algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "  p=np.arange(10,100,5)\n",
        "  hyperpara=dict(n_neighbors=n_neighbors,weights=weights,algorithm=algorithm,p=p)\n",
        "  KNN = RandomizedSearchCV(Kneig,hyperpara,cv=5,verbose=0,scoring='precision').fit(X,y)\n",
        "  p=np.arange(2,20,2)\n",
        "  return KNN\n",
        "\n",
        "def XGBoost_(X,y):\n",
        "  \n",
        "  xgb=XGBClassifier()\n",
        "  n_estimators=np.arange(1,200,50)\n",
        "  silent=[True,False]\n",
        "  max_depth=np.arange(3,12,1)  \n",
        "  booster=['gbtree','gblinear','dart']\n",
        "\n",
        "  hyperpara=dict(n_estimators=n_estimators,silent=silent,max_depth=max_depth)\n",
        "  XGB = RandomizedSearchCV(xgb,hyperpara,verbose=0,scoring='precision').fit(X,y)\n",
        "  return XGB\n",
        "\n",
        "def SVC_(X,y):\n",
        "  \n",
        "  Sscaler=StandardScaler()\n",
        "  X=Sscaler.fit_transform(X)\n",
        "  svc=SVC(kernel='rbf',random_state=0,gamma=1,C=1)\n",
        "  C=np.arange(1,10,0.5)\n",
        "  kernel=['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
        "  hyperpara=dict()\n",
        "  SCV = RandomizedSearchCV(svc,hyperpara,verbose=0,scoring='precision').fit(X,y)\n",
        "  return SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vIXELrdoxh",
        "colab_type": "code",
        "outputId": "2b4d0877-e726-4555-9faf-6916bc55e2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import joblib\n",
        "import os.path\n",
        "joblib.dump(Log_reg(X_train,y_train),'osmpl_Log_Reg.pkl')\n",
        "joblib.dump(Rand_forest(X_train,y_train),'osmpl_Rand_forest.pkl')\n",
        "#joblib.dump(KNeig(X,y),'osmpl_KNeig.pkl')\n",
        "joblib.dump(XGBoost_(X_train,y_train),'osmpl_XGBoost_.pkl')\n",
        "joblib.dump(SVC_(X_train,y_train),'osmpl_SVC_.pkl')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b9983c7ac2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRand_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'osmpl_Rand_forest.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#joblib.dump(KNeig(X,y),'osmpl_KNeig.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBoost_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'osmpl_XGBoost_.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'osmpl_SVC_.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-ba578165001f>\u001b[0m in \u001b[0;36mXGBoost_\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mhyperpara\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   \u001b[0mXGB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperpara\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mXGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07nNNZU-SJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_of_models(x, y, list_of_models):\n",
        "    results = [model_summary(model, x, y) for model in list_of_models]\n",
        "    results = pd.DataFrame(results)\n",
        "    return results\n",
        "\n",
        "def model_summary(model, x, y):\n",
        "  \n",
        "  y_pred=model.predict(x)\n",
        "\n",
        "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  precision=precision_score(y_test,y_pred)\n",
        "  accuracy=accuracy_score(y_test,y_pred)\n",
        "  recall=recall_score(y_test,y_pred)\n",
        "  f1=f1_score(y_test,y_pred)\n",
        "  auc=roc_auc_score(y_test, y_pred)\n",
        "  fpr, tpr, trashhold = roc_curve(y_test,  y_pred)\n",
        "\n",
        "  result = {'model': str(model),\n",
        "            'confusion matrix': cnf_matrix,\n",
        "            'precision': precision,\n",
        "            'accuracy': accuracy,\n",
        "            'recall': recall,\n",
        "            'f1 score': f1,\n",
        "            'auc': auc,\n",
        "            'fpr': fpr,\n",
        "            'tpr': tpr,\n",
        "            'trashhold': trashhold,\n",
        "              }\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRFu7gzp9jIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "osmpl_LR = load('/content/osmpl_Log_Reg.pkl')\n",
        "osmpl_RF = load('/content/osmpl_Rand_forest.pkl')\n",
        "#osmpl_XGB = load('/content/osmpl_XGBoost_.pkl')\n",
        "#osmpl_SVC = load('/content/osmpl_SVC_.pkl')\n",
        "models=(osmpl_LR,osmpl_RF)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq9q3iXl-igV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test.csv')\n",
        "#df_test = pd.read_csv('/content/drive/My Drive/Data Science/ML fraud detection/test.csv')\n",
        "df_test['scaled_time']=round((df['Time']/3600)%24)\n",
        "Rob_scaler = RobustScaler()\n",
        "df_test['scaled_Amount']=Rob_scaler.fit_transform(df_test['Amount'].values.reshape(-1,1))\n",
        "df_test = df_test.drop(['Time','Amount'],axis=1)\n",
        "X_test = df_test.drop(columns=['Class'])\n",
        "y_test = df_test['Class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf1W3epbDSJR",
        "colab_type": "code",
        "outputId": "1709ad79-5184-4d03-8366-f2c3927f5059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "a=performance_of_models(X_test, y_test, models)\n",
        "a"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>confusion matrix</th>\n",
              "      <th>precision</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1 score</th>\n",
              "      <th>auc</th>\n",
              "      <th>fpr</th>\n",
              "      <th>tpr</th>\n",
              "      <th>trashhold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomizedSearchCV(cv=5, error_score='raise-de...</td>\n",
              "      <td>[[1150, 69929], [0, 123]]</td>\n",
              "      <td>0.001756</td>\n",
              "      <td>0.017879</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003506</td>\n",
              "      <td>0.508090</td>\n",
              "      <td>[0.0, 0.9838208190886197, 1.0]</td>\n",
              "      <td>[0.0, 1.0, 1.0]</td>\n",
              "      <td>[2, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomizedSearchCV(cv=5, error_score='raise-de...</td>\n",
              "      <td>[[1151, 69928], [0, 123]]</td>\n",
              "      <td>0.001756</td>\n",
              "      <td>0.017893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003506</td>\n",
              "      <td>0.508097</td>\n",
              "      <td>[0.0, 0.9838067502356533, 1.0]</td>\n",
              "      <td>[0.0, 1.0, 1.0]</td>\n",
              "      <td>[2, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               model  ...  trashhold\n",
              "0  RandomizedSearchCV(cv=5, error_score='raise-de...  ...  [2, 1, 0]\n",
              "1  RandomizedSearchCV(cv=5, error_score='raise-de...  ...  [2, 1, 0]\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udAvria-5uDO",
        "colab_type": "code",
        "outputId": "3677220a-eb20-4f29-afc4-040db06337cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "osmpl_LR = load('/content/osmpl_Log_Reg.pkl')\n",
        "osmpl_RF = load('/content/osmpl_Rand_forest.pkl')\n",
        "osmpl_XGB = load('/content/osmpl_XGBoost_.pkl')\n",
        "osmpl_SVC = load('/content/osmpl_SVC_.pkl')\n",
        "\n",
        "def eclf(X_train, y_train, list_of_modelspkl, list_of_weights):\n",
        "  clfs = EnsembleVoteClassifier(clfs=list_of_modelspkl, voting='hard', refit=False, weights=list_of_weights)\n",
        "  return clfs.fit(X_train, y_train)\n",
        "\n",
        "list_of_modelspkl = [osmpl_LR, osmpl_RF, osmpl_XGB]\n",
        "list_of_weights = [1, 1, 2]\n",
        "\n",
        "d = eclf(X,y, list_of_modelspkl, list_of_weights)\n",
        "\n",
        "dump(eclf, 'osmpl_eclf.pkl')\n",
        "\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnsembleVoteClassifier(clfs=[GridSearchCV(cv='warn',\n",
              "                                          error_score='raise-deprecating',\n",
              "                                          estimator=LogisticRegression(C=1.0,\n",
              "                                                                       class_weight=None,\n",
              "                                                                       dual=False,\n",
              "                                                                       fit_intercept=True,\n",
              "                                                                       intercept_scaling=1,\n",
              "                                                                       l1_ratio=None,\n",
              "                                                                       max_iter=100,\n",
              "                                                                       multi_class='warn',\n",
              "                                                                       n_jobs=None,\n",
              "                                                                       penalty='l2',\n",
              "                                                                       random_state=None,\n",
              "                                                                       solver='warn',\n",
              "                                                                       tol=0.0001,\n",
              "                                                                       verbose=0,\n",
              "                                                                       warm_start=False),\n",
              "                                          iid='warn', n_jobs=Non...\n",
              "                                                                  reg_alpha=0,\n",
              "                                                                  reg_lambda=1,\n",
              "                                                                  scale_pos_weight=1,\n",
              "                                                                  seed=None,\n",
              "                                                                  silent=None,\n",
              "                                                                  subsample=1,\n",
              "                                                                  verbosity=1),\n",
              "                                          iid='warn', n_jobs=None,\n",
              "                                          param_grid={'n_estimators': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19]),\n",
              "                                                      'silent': [True, False]},\n",
              "                                          pre_dispatch='2*n_jobs', refit=True,\n",
              "                                          return_train_score=False,\n",
              "                                          scoring=None, verbose=0)],\n",
              "                       refit=False, verbose=0, voting='hard',\n",
              "                       weights=[1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErchttixAAlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}